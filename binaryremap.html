<!DOCTYPE html>
<html lang="en">
	<head>
		<title>free performance with mmap.</title>
<style>
pre {
    border: 2px solid green;
}
</style>
	</head>
	<body style="font-family: monospace;background-color: #000000; color: #FFFFFF" link='green' vlink='green' alink='green'>
		<p>
		<a href="index.html">[home]</a>
		<a href="index.html/#fun">[sandbox]</a>
		<a href="#resume">[resume]</a>
		<a href="#contact">[contact]</a>
		</p>
		<hr>
        <p id="blog">
        <h1>performance tuning without changing anything</h1>
        When performance tuning at scale, cache misses and table walks can be killer.
        A cache miss is when whatever memory you're accessing isn't readily available in your L1 cache, you "miss" and look to the next layer, and so on. Eventually hitting the dreaded DRAM and hopefully never making it to disk (swap).
        <br>
        This <a href="https://cs.stackexchange.com/questions/102834/what-is-happening-during-table-walk">stackexchange</a> question/answer nicely
        explains what happens during a table walk. The tldr is that we need to translate between virtual and physical memory but it isn't a direct 1:1 mapping. In our program we may dereference a pointer to manipulate a value
        at some address but in reality that is a virtual address that must get translated to a physical address. Virtual memory is stored within pages which are typically 4096 bytes in size (standard 64-bit linux page size).
        When your memory access is not on the current page accessible, we must walk our table to find the page with the memory we want to access and then translate for the physical page which is a multi-level pointer chase. As
        you can probably imagine, these lookups and loads are not cheap especially when you care about optimizing your operations.
        <h1>huge pages</h1>
        So I mentioned that your memory is mapped into pages of size 4096. If you work with any enterprise scale application chances are the full instructions and data do not fit into a nicely packed single 4K page. Meaning you
        risk table walking depending on what you are doing, like a far jump or resolving very large hash table entry buckets. A very simple question one may ask is "can we make the virtual pages bigger?".
        <br>
        Yes.
        <br>
        Sort of.
        <br>
        In 64-bit Linux land depending on your kernel version you have access to what are called huge pages. A peek at the <a href="https://www.man7.org/linux/man-pages/man2/mmap.2.html">manual page for mmap</a> talks a bit about
        these huge pages with the MAP_HUGE_2MB and MAP_HUGE_1GB flags. First you'll need to see if your system supports it and what is configured exactly.
        <pre>
        <code>
    $ grep -i huge /proc/meminfo
    AnonHugePages:         0 kB
    ShmemHugePages:        0 kB
    FileHugePages:         0 kB
    HugePages_Total:       0
    HugePages_Free:        0
    HugePages_Rsvd:        0
    HugePages_Surp:        0
    Hugepagesize:       2048 kB
    Hugetlb:               0 kB
        </code></pre>
        Nice so my system has huge pages configured to 2MB (2048kB) but it isn't using any at all. On a desktop machine this makes sense, usually server variants of an OS will have them default configured. To see if they are
        enabled:
        <pre>
        <code>
    $ cat /sys/kernel/mm/transparent_hugepage/enabled
    always [madvise] never
        </code></pre>
        This output shows 3 options and the one inside the square brackets is currently selected. In this case huge pages can be used (if they exist) when madvise notes to try. For the unfamiliar
        <a href="https://www.man7.org/linux/man-pages/man2/madvise.2.html">madvise</a> is a system call to give advice to the kernel about the address range provided. One such advice is MADV_HUGEPAGE which enables transparent
        huge pages for the pages in the range specified. This means that as the kernel scans areas marked as huge page candidates it will attempt to allocate and replace them. Handy way of letting the kernel do the magic.
        <br>
        <br>
        The thing is there are no huge pages available to use on my system, so that madvise option isn't going to do anything. We could change that to [always] of course but still same problem. So lets tell the OS to have some
        huge pages. Before you do this make sure that you have the available memory, and calculate how many you will need. For this experiment I will make a single page but in a real environment you'll want many more. If you
        get this value wrong or try to access huge pages that don't exist you can enter some unfortunate state in your application or even OS. <a href="https://oracle-base.com/articles/linux/configuring-huge-pages-for-oracle-on-linux-64">Oracle</a> has a very useful guide for this exact task but comes with the context of managing Oracle on Linux so I'll keep it brief and skip all that fluff.
        <pre>
        <code>
    # open /etc/sysctl.conf with your favorite editor (it is vim right?)
    # update or add this line for a single huge page
    vm.nr_hugepages=1
    # save and exit then run the following command to refresh this system config
    sysctl -p
        </code></pre>
        We have now configured our machine to have a whopping 1 huge page (2MB in size). We can verify by checking out meminfo again:
        <pre>
        <code>
    $ grep -i hugepages /proc/meminfo 
    AnonHugePages:         0 kB
    ShmemHugePages:        0 kB
    FileHugePages:         0 kB
    HugePages_Total:       1
    HugePages_Free:        1
    HugePages_Rsvd:        0
    HugePages_Surp:        0
    Hugepagesize:       2048 kB
        </code></pre>
        Voila. There it is. Let's use it!
        <h1>remap running code</h1>
        I wasn't exactly honest when I said we can get some performance gains by changing nothing. So far we had to change our system configuration, and now we will modify our program we are optimizing but not by changing algorithms or
        data structure choices. Instead we will focus on our actual code leaving out the data for now. After this exercise, how to make your static and dynamic allocations use huge pages should be obvious. We are going to take our text
        section of the running ELF binary and change it from regular sized pages to huge pages so that ideally our instructions all fit on a single page never needing a table walk, and if we arrange things optimally then you could
        reduce cache misses further by retaining it in cache.
        <br>
        <br>
        Searching the internet there are tools that will do the remapping for you. But where's the fun in that when we have already done the configuration manually?
        </p>
		<p id="contact">
		<hr>
		e-mail: <a href="/cdn-cgi/l/email-protection#9ff2f6fcf7fefaf3fcf0feebfaecdfefedf0ebf0f1f2fef6f3b1fcf0f2"><span class="__cf_email__" data-cfemail="1d70747e757c78717e727c69786e5d6d6f72697273707c7471337e7270">[email&#160;protected]</span></a><br>
		</p>
	<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script></body>
    </body>
</html>
